{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"; span style=\"color:#336699\"><b><h2>pyForTraCC - Radar Data Track Exemple</h2></b></div>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "<br/>\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "   <sup><a href=\"https://www.linkedin.com/in/helvecio-leal/\"> Helvécio B. Leal Neto, <i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup><t>&nbsp;</t> \n",
    "    <sup><a href=\"https://www.linkedin.com/in/alan-calheiros-64a252160/\">Alan J. P. Calheiros<i class=\"fab fa-lg fa-orcid\" style=\"color** #a6ce39\"></i></a></sup>\n",
    "   <br/><br/>\n",
    "    National Institute for Space Research (INPE)\n",
    "    <br/>\n",
    "    Avenida dos Astronautas, 1758, Jardim da Granja, São José dos Campos, SP 12227-010, Brazil\n",
    "    <br/><br/>\n",
    "    Contact: <a href=\"mailto:helvecio.neto@inpe.br\">helvecio.neto@inpe.br</a>, <a href=\"mailto:alan.calheiros@inpe.br\">alan.calheiros@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Last Update: Feb 12, 2025\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
    "<b>Abstract.</b> This Jupyter notebook demonstrates the track process for a Radar Data and show some utilities of the pyForTraCC algorithm.\n",
    "</div>    \n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>This notebook is part of the <a href=\"https://github.com/fortracc/pyfortracc\">pyfortracc</a> examples gallery</b>\n",
    "    <div style=\"margin-left: 10px; margin-right: 10px; margin-top:10px\">\n",
    "      <p> Leal Neto, H.B.; Calheiros, A.J.P.;  pyForTraCC Algorithm. São José dos Campos, INPE, 2024. <a href=\"https://github.com/fortracc-project/pyfortracc\" target=\"_blank\"> Online </a>. </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule\n",
    "\n",
    " [1. Installation](#install)<br>\n",
    " [2. Radar Input Data](#data)<br>\n",
    " [3. Read Function](#read)<br>\n",
    " [4. Tracking Parameters](#parameters)<br>\n",
    " [5. Tracking Routine](#track)<br>\n",
    " [6. Tracking Table](#tracktable)<br>\n",
    " [7. Spatial Conversions](#visualization)<br>\n",
    " [8. Explore Results](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='install'></a>\n",
    "#### 1. Installation\n",
    "\n",
    "Installing the pyFortraCC package can be done using the pip install command. \n",
    "\n",
    "All dependencies will be installed in the current Python environment and the code will be ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install latest version of pyfortracc\n",
    "!python -m pip install -q -U pyfortracc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and check pyfortracc version\n",
    "import pyfortracc\n",
    "print(f'pyfortracc version: {pyfortracc.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "#### 1. Radar Input Data\n",
    "\n",
    "The data in this example corresponds to a small sample of scans from the S-Band Radar located in the city of Manaus-AM Brazil.<br>\n",
    " Data processed and published by Schumacher, Courtney and Funk, Aaron (2018) were separated, <br>\n",
    " and are available in full on the ARM platform https://www.arm.gov/research/campaigns/amf2014goamazon.<br>\n",
    " This data is part of the GoAmazon2014/5 project and is named \"Three-dimensional Gridded S-band Reflectivity and Radial Velocity<br>\n",
    " from the SIPAM Manaus S-band Radar dataset\".<br>\n",
    "https://doi.org/10.5439/1459573\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example input files\n",
    "!python -m pip install -q -U gdown\n",
    "\n",
    "import gdown, zipfile, os, shutil\n",
    "\n",
    "# Remove the existing input files\n",
    "shutil.rmtree('input', ignore_errors=True)\n",
    "\n",
    "# Download the input files\n",
    "url = 'https://drive.google.com/uc?id=1UVVsLCNnsmk7_wOzVrv4H7WHW0sz8spg'\n",
    "gdown.download(url, 'input.zip', quiet=False)\n",
    "with zipfile.ZipFile('input.zip', 'r') as zip_ref:\n",
    "    for member in zip_ref.namelist():\n",
    "        zip_ref.extract(member)\n",
    "os.remove('input.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read'></a>\n",
    "#### 3. Read Function\n",
    "\n",
    "The downloaded data is compressed with the .gz extension, however, it is of the netCDF4 type. The variable that represents reflectivity is DBZc. This data also has multiple elevations, and we arbitrarily chose elevation 5, which corresponds to the volumetric scan level at 2.5 km height. We extract the data and apply a NaN value to the data mask -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Read function\n",
    "import gzip\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "\n",
    "def read_function(path):\n",
    "    variable = \"DBZc\"\n",
    "    z_level = 5 # Elevation level 2.5 km\n",
    "    with gzip.open(path) as gz:\n",
    "        with netCDF4.Dataset(\"dummy\", mode=\"r\", memory=gz.read()) as nc:\n",
    "            data = nc.variables[variable][:].data[0,z_level, :, :][::-1, :]\n",
    "            data[data == -9999] = np.nan\n",
    "    gz.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data, we use an function from pyFortraCC that reads the data and create an animation of the radar scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfortracc import plot_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data using the plot_animation function\n",
    "plot_animation(path_files='input/*.gz', # Path to the files\n",
    "                          read_function=read_function, # Read function\n",
    "                          num_frames=10, min_val=0, max_val=60, # Number of frames and maximum value\n",
    "                          cbar_title='dBZ') # Colorbar title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameters'></a>\n",
    "#### 4. Tracking Parameters (Name List)\n",
    "\n",
    "For this example, we will track reflectivity clusters at multiple thresholds and sizes <br>Arbitrarily selecting thresholds of 20, 30 and 35 dBZ with clusters of 5,4 and 3 pixels <br>of minimum size. The segmentation operator will be >=, that is, the clusters will be <br>segmented in order of greatest equal for each threshold and the delta of the observations <br>is 12 minutes.<br>\n",
    "\n",
    "*   ***Clustering Method***: The algorithm have two clustering methods, the first is the ndimage.label method, and the second is the ***DBSCAN*** method. The ndimage.label method is a simple method that labels the clusters in the image, while the DBSCAN method is a more complex method that uses the DBSCAN algorithm to find contiguous pixels connected by a spatial distance (epsilon). The DBSCAN method is more robust and can be used to track clusters in a more complex way. For this example, we will use the DBSCAN method with epsilon = 3 pixels of spatial distance to find the clusters.\n",
    "\n",
    "*   ***Vector Correction Methods***: Several factors can modify rain cell movement when analyzing their trajectory. One of these factors that can affect a reasonable estimate of displacement trajectory is the use of a centroid as a target. This problem is associated with the shape of tracked objects and processes of mergers and splits that may occur during the development of precipitating systems, These problem are covered in the work https://doi.org/10.3390/rs14215408. For this example, we will use the Split, Merge, Inner Cores, Optical Flow and Ellipse methods find the best vector for the tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Name list dictionary of mandatory parameters\n",
    "name_list = {}\n",
    "name_list['input_path'] = 'input/' # path to the input data\n",
    "name_list['output_path'] = 'output/' # path to the output data\n",
    "name_list['timestamp_pattern'] = 'sbmn_cappi_%Y%m%d_%H%M.nc.gz' # timestamp file pattern\n",
    "name_list['thresholds'] = [20, 30, 35] # in dbz\n",
    "name_list['min_cluster_size'] = [5,4,3] # in number of points per cluster\n",
    "name_list['operator'] = '>=' # '>= *   **<=' or '=='\n",
    "name_list['delta_time'] = 12 # in minutes\n",
    "name_list['min_overlap'] = 20 # Minimum overlap between clusters in percentage\n",
    "\n",
    "# Clustering method\n",
    "name_list['cluster_method'] = 'dbscan' # DBSCAN Clustering method\n",
    "name_list['eps'] = 3 # in pixels\n",
    "\n",
    "# Vector correction methods\n",
    "name_list['spl_correction'] = True # Perform the Splitting events\n",
    "name_list['mrg_correction'] = True # Perform the Merging events\n",
    "name_list['inc_correction'] = True # Perform the Inner Core vectors\n",
    "name_list['opt_correction'] = True # Perform the Optical Flow method (New Method)\n",
    "name_list['elp_correction'] = True # Perform the Ellipse method (New Method)\n",
    "name_list['validation'] = True # Perform the validation of the best correction between times (t-1 and t)\n",
    "\n",
    "# Optional parameters, if not set, the algorithm will not use geospatial information\n",
    "name_list['lon_min'] = -62.1475 # Min longitude of data in degrees\n",
    "name_list['lon_max'] = -57.8461 # Max longitude of data in degrees\n",
    "name_list['lat_min'] = -5.3048 # Min latitude of data in degrees\n",
    "name_list['lat_max'] = -0.9912 # Max latitude of data in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyfortracc module\n",
    "import pyfortracc as pf\n",
    "\n",
    "# Track the clusters\n",
    "pf.track(name_list, read_function, parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trackingtable'></a>\n",
    "#### 5. Tracking Table\n",
    "\n",
    "The output of concatenate is a entity called tracking table. The tracking table is the generalized output  located in the output directory of name_list['output'] ('output_path/trackingtable'). The information obtained in the tracking process is stored in a tabular format, and is organized according to the tracking time. Listed below are the names of the columns (output variables) and what they represent.\n",
    "\n",
    "*   Each row of tracking table is related to a cluster at its corresponding threshold level. \n",
    "*   The Tracking table structure provides a comprehensive view of grouped entities, facilitating analysis and understanding of patterns across different threshold levels.\n",
    "\n",
    "Tracking table columns:\n",
    "\n",
    "*   **timestamp** (datetime64[us]): Temporal information of cluster.\n",
    "*   **uid** (float64): Unique idetifier of cluster.\n",
    "*   **iuid** (float64): Internal Unique idetifier of cluster.\n",
    "*   **threshold_level** (int64): Level of threshold.\n",
    "*   **threshold** (float64): Specific threshold.\n",
    "*   **status** (object): Entity status (NEW, CONTINUOUS, SPLIT, MERGE, SPLIT/MERGE)\n",
    "*   **u_, v_** (float64): Vector components.\n",
    "*   **inside_clusters** (object): Number of inside clusters.\n",
    "*   **size** (int64): Cluster size in pixels.\n",
    "*   **min, mean, max, std** (float64): Descriptive statistics.\n",
    "*   **delta_time** (timedelta64[us]): Temporal variation.\n",
    "*   **file** (object): Associated file name.\n",
    "*   **array_y, array_x** (object): Cluster array coordinates.\n",
    "*   **vector_field** (object): Associated vector field.\n",
    "*   **trajectory** (object): Cluster's trajectory.\n",
    "*   **geometry** (object):  Boundary geometric representation of the cluster.\n",
    "*   **lifetime** (int64): Cluster lifespan in minutes.\n",
    "*   **vector_field** The vector field of the cluster (MultiLineString).\n",
    "*   **expansion** The expansion rate between the clusters of consecutive times.\n",
    "*   **u_spl** The u component of the cluster by Split Correction.\n",
    "*   **v_spl** The v component of the cluster by Split Correction.\n",
    "*   **u_mrg** The u component of the cluster by Merge Correction.\n",
    "*   **v_mrg** The v component of the cluster by Merge Correction.\n",
    "*   **u_inc** The u component of the cluster by Inner Cores Correction.\n",
    "*   **v_inc** The v component of the cluster by Inner Cores Correction.\n",
    "*   **u_opt** The u component of the cluster by Optical Flow Correction.\n",
    "*   **v_opt** The v component of the cluster by Optical Flow Correction.\n",
    "*   **u_elp** The u component of the cluster by Elliptical Correction.\n",
    "*   **v_elp** The v component of the cluster by Elliptical Correction.\n",
    "*   **u_noc** The u component of the cluster by No Correction.\n",
    "*   **v_noc** The v component of the cluster by No Correction.\n",
    "*   **far** The False Alarm Rate of method, if the validation is True into a name_list.\n",
    "*   **method** The best method of correction, if the validation is True into a name_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple way to visualize the tracking table is to use the duckdb library to create a database and query the table. The duckdb library is a simple and efficient library for creating databases in Python. DuckDB uses the SQL language to query the database, and the pandas library to create the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to the database\n",
    "con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# Read and filter the data from track table\n",
    "tracking_table = con.execute(f\"\"\"SELECT * \n",
    "                             FROM parquet_scan('output/track/trackingtable/*.parquet',\n",
    "                             union_by_name=True)\n",
    "                             \"\"\").fetch_df()\n",
    "# Display the tracking table\n",
    "display(tracking_table.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='convect'></a>\n",
    "### 6. Convert Tracking Table to GeoSpatial Data\n",
    "\n",
    "pyForTraCC has a utility function that converts the tracking table to a GeoSpatial data format. These functions are useful for creating shapefiles, GeoJSON, and other spatial data formats. The converted data can be visualized in a GIS software like QGIS or ArcGIS. The output files are saved in the output directory of name_list['output']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyfortracc.spatial_conversions module\n",
    "from pyfortracc.spatial_conversions import boundaries, trajectories, vectorfield, clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows how to convert the tracking table cluster boundaries, trajectories and vector field to a GeoSpatial data format. To check the converted data, you can view into the output directory of `name_list['output']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The output path is:', name_list['output_path'] + 'geometry/')\n",
    "\n",
    "# Get the boundaries of tracked clusters\n",
    "boundaries(name_list=name_list,\n",
    "           start_time=str(tracking_table.timestamp.min()),\n",
    "           end_time=str(tracking_table.timestamp.max()),\n",
    "           driver='GeoJSON')\n",
    "\n",
    "# Get the trajectories of tracked clusters\n",
    "trajectories(name_list=name_list,\n",
    "             start_time=str(tracking_table.timestamp.min()),\n",
    "             end_time=str(tracking_table.timestamp.max()),\n",
    "             driver='GeoJSON')\n",
    "\n",
    "# Get the vector field of tracked clusters\n",
    "vectorfield(name_list=name_list,\n",
    "             start_time=str(tracking_table.timestamp.min()),\n",
    "             end_time=str(tracking_table.timestamp.max()),\n",
    "             driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracked cluster can be converted to netCDF format using the function `clusters`. The function converts the clusters from tracking table to a netCDF file. Each individual cluster is saved into with the cluster's UID content into the Band variable. The output file is saved in the output directory of `name_list['output']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters(name_list=name_list,\n",
    "         read_function=read_function,\n",
    "         start_time=str(tracking_table.timestamp.min()),\n",
    "         end_time=str(tracking_table.timestamp.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "#### 7. Explore the results in tracking table\n",
    "\n",
    "To explore the results of the tracking process, we can use the tracking table. For this example, we will find the with a max lifetime and explore the results showing the track process using animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two maxlifetime clusters from the track_table\n",
    "maxlifetime = 2\n",
    "max_lifetimes = tracking_table.groupby('uid').size().nlargest(maxlifetime).index.values\n",
    "max_clusters = tracking_table[tracking_table['uid'].isin(max_lifetimes)]\n",
    "print('The clusters with the highest lifetime are the uids: {}'.format(max_lifetimes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the maxlifetime system in the tracking table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as animation. (obs: if run in colab, the animation could be fail sometimes, run again to fix)\n",
    "plot_animation(read_function=read_function, # Read function\n",
    "                          name_list=name_list, # Name list dictionary\n",
    "                          uid_list=max_lifetimes.tolist(), # List of uids\n",
    "                          start_timestamp = max_clusters['timestamp'].min().strftime('%Y-%m-%d %H:%M:%S'), \n",
    "                          end_timestamp= max_clusters['timestamp'].max().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                          cbar_title='dBZ', # Colorbar title\n",
    "                          threshold_list=[20], # Threshold list\n",
    "                          trajectory=True, # Plot the trajectory\n",
    "                          max_val=60, # Maximum value for the colorbar\n",
    "                          min_val=20, # Minimum value for the colorbar\n",
    "                          info_cols=['uid','method','far'], # Information columns from the tracking table\n",
    "                          background='google', # Background type: 'default', 'stock', satellite' or 'google'\n",
    "                          traj_color='red', # Trajectory color\n",
    "                          parallel=False\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfortracc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
